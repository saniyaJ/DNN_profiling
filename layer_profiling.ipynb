{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go_nwb06ApMy"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torchvision \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import numpy\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root='/data',train=True,download=True,transform=train_transforms)\n",
        "test_data = torchvision.datasets.CIFAR10(root='/data',train=False,download=True,transform=test_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_ecUi1gDiX5",
        "outputId": "f3f90246-194b-4b87-cdf6-297211c98faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv Model"
      ],
      "metadata": {
        "id": "z1nzsjh4MZdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_model(Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.cnn_layer=Sequential(\n",
        "        Conv2d(1024, 512, kernel_size=3, stride=1, padding=1),\n",
        "        Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "        Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "        Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "        Linear(256,10)\n",
        "    )\n",
        "  def forward(self,input):\n",
        "    return self.cnn_layer(input)\n",
        "    "
      ],
      "metadata": {
        "id": "g2tBf3gsySK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model1 = torchvision.models.resnet18(pretrained=True)\n",
        "#num_ftrs = model1.fc.in_features\n",
        "#model1.fc = torch.nn.Linear(num_ftrs, 10)\n",
        "#model1.to(device)\n",
        "model1=cnn_model().to(device)"
      ],
      "metadata": {
        "id": "9MwwTDgwKH8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cpu()\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=0.001, momentum=0.9)\n",
        "train_losses=[]\n",
        "i=0\n",
        "with profile(activities=[ProfilerActivity.CPU],profile_memory=True, record_shapes=True) as prof:\n",
        "  train_loss=0\n",
        "  for step, batch_data in enumerate(train_loader): \n",
        "    if i==10:\n",
        "      break\n",
        "    inputs, labels = batch_data[0].to(device=device), batch_data[1].to(device=device)\n",
        "    outputs = model1(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    train_loss+=loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    i+=1\n",
        "    \n",
        "  train_losses.append(train_loss/len(train_loader))\n",
        "  print('Total loss: ',np.mean(train_losses))\n",
        "    \n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ZtegexwLXA",
        "outputId": "f58af87d-6936-4394-b702-4628e32a4106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss:  0.06016756445550553\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         0.25%      61.221ms         0.25%      61.221ms       5.105us       1.58 Gb       1.58 Gb         11992  \n",
            "                               aten::threshold_backward         0.41%     102.181ms         0.41%     102.181ms     601.065us     230.00 Mb     230.00 Mb           170  \n",
            "                 aten::max_pool2d_with_indices_backward         0.09%      22.905ms         0.19%      47.364ms       4.736ms      80.00 Mb      80.00 Mb            10  \n",
            "                                    aten::empty_strided         0.21%      51.664ms         0.21%      51.664ms       6.718us      65.71 Mb      65.71 Mb          7690  \n",
            "                          aten::max_pool2d_with_indices         1.19%     294.676ms         1.19%     294.676ms      29.468ms      60.00 Mb      60.00 Mb            10  \n",
            "                                              aten::div         0.09%      22.447ms         0.15%      37.435ms      26.400us      19.00 Mb      18.99 Mb          1418  \n",
            "                                              aten::cat         0.02%       5.622ms         0.02%       5.622ms     511.091us      16.50 Mb      16.50 Mb            11  \n",
            "                                       aten::empty_like         0.04%       9.345ms         0.09%      21.752ms      10.779us     742.88 Mb      10.53 Mb          2018  \n",
            "                                            aten::clone         0.08%      18.551ms         0.43%     105.425ms      36.631us      63.28 Mb       9.70 Mb          2878  \n",
            "                                               aten::mm         0.01%       1.898ms         0.01%       1.898ms      94.900us       2.70 Mb       2.70 Mb            20  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 24.711s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG Model"
      ],
      "metadata": {
        "id": "rTNAnqKSMWht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model2 = torchvision.models.vgg11(pretrained=True)\n",
        "criterion = torch.nn.CrossEntropyLoss().cpu()\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=0.001, momentum=0.9)\n",
        "model2.to(device)\n",
        "train_losses=[]\n",
        "i=0\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],profile_memory=True, record_shapes=True) as prof:\n",
        "  train_loss=0\n",
        "  for step, batch_data in enumerate(train_loader): \n",
        "    if i==5:\n",
        "      break\n",
        "    inputs, labels = batch_data[0].to(device=device), batch_data[1].to(device=device)\n",
        "    outputs = model2(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    train_loss+=loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    i+=1\n",
        "  train_losses.append(train_loss/len(train_loader))\n",
        "  print('Total loss: ',np.mean(train_losses))\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "id": "Mk19wT6TL9tQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e681b1-8eb0-4602-b6d0-733fc348de2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/autograd/profiler.py:179: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss:  0.13966851100287475\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                               aten::mm        21.72%        7.939s        21.72%        7.939s     264.633ms       2.38 Gb       2.38 Gb            30  \n",
            "                                            aten::empty         0.04%      15.336ms         0.04%      15.336ms       3.145us     728.50 Mb     728.50 Mb          4877  \n",
            "                                    aten::empty_strided         0.03%      11.313ms         0.03%      11.313ms       2.853us     524.08 Mb     524.08 Mb          3965  \n",
            "                               aten::threshold_backward         0.82%     300.851ms         0.82%     300.851ms       6.017ms     390.00 Mb     390.00 Mb            50  \n",
            "                 aten::max_pool2d_with_indices_backward         0.20%      71.663ms         0.45%     166.049ms       6.642ms     305.00 Mb     305.00 Mb            25  \n",
            "                          aten::max_pool2d_with_indices         1.80%     657.233ms         1.80%     657.233ms      26.289ms     228.75 Mb     228.75 Mb            25  \n",
            "                                          aten::resize_         0.00%     137.000us         0.00%     137.000us      11.417us      62.50 Mb      62.50 Mb            12  \n",
            "                                              aten::mul         0.05%      16.868ms         0.05%      16.868ms     843.400us      40.00 Mb      40.00 Mb            20  \n",
            "                                            aten::addmm        11.60%        4.242s        11.62%        4.248s     283.210ms      22.44 Mb      22.44 Mb            15  \n",
            "                                              aten::cat         0.01%       2.659ms         0.01%       2.659ms     443.167us       9.00 Mb       9.00 Mb             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 36.558s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "!pip install onnxoptimizer"
      ],
      "metadata": {
        "id": "uuJMHD2Vzb-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a638ef9b-08bd-41aa-cde0-023a027504d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.13.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.11.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.3.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.0)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxoptimizer\n",
            "  Downloading onnxoptimizer-0.3.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.9/671.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (from onnxoptimizer) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxoptimizer) (4.5.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxoptimizer) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxoptimizer) (1.22.4)\n",
            "Installing collected packages: onnxoptimizer\n",
            "Successfully installed onnxoptimizer-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run time with onyx decrease"
      ],
      "metadata": {
        "id": "CvYeqABL3fud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"vgg16-7.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "for step, batch_data in enumerate(train_loader): \n",
        "  inputs, labels = batch_data[0].to(device=device), batch_data[1].to(device=device)\n",
        "  break\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(inputs)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "torch_out = model2(inputs) \n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)"
      ],
      "metadata": {
        "id": "RJKX5drt3i5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized Onyx run time decreased further"
      ],
      "metadata": {
        "id": "cHF5Isfp3mJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m onnxoptimizer vgg16-7.onnx vgg16-7_opt.onnx"
      ],
      "metadata": {
        "id": "x4lX7MgywuA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from time import perf_counter\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "def time_ort_model_evaluation(model_path):\n",
        "    sess_options = onnxruntime.SessionOptions()\n",
        "    sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "    session = onnxruntime.InferenceSession(model_path, sess_options)\n",
        "\n",
        "    time_per_inference = []\n",
        "    for _ in range(10):\n",
        "        \n",
        "        # compute ONNX Runtime output prediction\n",
        "        ort_inputs = {session.get_inputs()[0].name: to_numpy(inputs)}\n",
        "        start = perf_counter()\n",
        "        session.run(None, ort_inputs)\n",
        "        time_per_inference.append((1000 * (perf_counter() - start)))\n",
        "\n",
        "    return np.mean(time_per_inference)\n",
        "\n",
        "print('Average runtime of ONNX Model in TPU: ' + str(time_ort_model_evaluation('vgg16-7.onnx')))\n",
        "print('Average runtime of ONNX Quantized Model in TPU: ' + str(time_ort_model_evaluation('vgg16-7_opt_quant.onnx')))\n"
      ],
      "metadata": {
        "id": "7_hrXj_axi-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}