{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a80da795c83f48fab095a781cbe4cde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f9cac5fc17043f5b7d682cf2082b586",
              "IPY_MODEL_aafbec91ae4c474ea34b48d816d70a77",
              "IPY_MODEL_c6213de5ec2b4546a150f052df2f94d4"
            ],
            "layout": "IPY_MODEL_307b89a8275e44488dc1f6d0b9489651"
          }
        },
        "3f9cac5fc17043f5b7d682cf2082b586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5b4f5b81554420aee12cb61f3bc1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_627eb6591b804cc1918e39442d5a3f60",
            "value": "100%"
          }
        },
        "aafbec91ae4c474ea34b48d816d70a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81fa4e70154042dfb2e9d24a7137f0f1",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bcd5fb8bb41476eb04fecead76aaee9",
            "value": 46830571
          }
        },
        "c6213de5ec2b4546a150f052df2f94d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592c567ffc244214b937378600b9891e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f0716494fdb466c952d1361b3cf4d41",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 71.9MB/s]"
          }
        },
        "307b89a8275e44488dc1f6d0b9489651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5b4f5b81554420aee12cb61f3bc1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627eb6591b804cc1918e39442d5a3f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81fa4e70154042dfb2e9d24a7137f0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bcd5fb8bb41476eb04fecead76aaee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "592c567ffc244214b937378600b9891e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0716494fdb466c952d1361b3cf4d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Installations"
      ],
      "metadata": {
        "id": "DitDzLNdp9BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import numpy as np\n",
        "from time import perf_counter\n",
        "\n",
        "from torch import nn\n",
        "import torchvision.models as models\n",
        "import torch.onnx"
      ],
      "metadata": {
        "id": "lLqDaqGnqKRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model and Data Load"
      ],
      "metadata": {
        "id": "WLTDoLfPqR5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)       # We now have an instance of the pretrained model"
      ],
      "metadata": {
        "id": "AEFWWL4-ecZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "a80da795c83f48fab095a781cbe4cde2",
            "3f9cac5fc17043f5b7d682cf2082b586",
            "aafbec91ae4c474ea34b48d816d70a77",
            "c6213de5ec2b4546a150f052df2f94d4",
            "307b89a8275e44488dc1f6d0b9489651",
            "ee5b4f5b81554420aee12cb61f3bc1f5",
            "627eb6591b804cc1918e39442d5a3f60",
            "81fa4e70154042dfb2e9d24a7137f0f1",
            "8bcd5fb8bb41476eb04fecead76aaee9",
            "592c567ffc244214b937378600b9891e",
            "8f0716494fdb466c952d1361b3cf4d41"
          ]
        },
        "outputId": "1d154737-eefc-4af3-d503-bf6b9185f7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a80da795c83f48fab095a781cbe4cde2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "dtvl0cKPedwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302b1949-111e-49f3-bb57-d95944f7cac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, 3, 224, 224)"
      ],
      "metadata": {
        "id": "obLsQMYeefha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX Compilation, Export, and ONNX Runtime Inference"
      ],
      "metadata": {
        "id": "S8ai_bodqZ6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = [ \"actual_input\" ]\n",
        "output_names = [ \"output\" ]\n",
        "\n",
        "torch.onnx.export(model,\n",
        "                 dummy_input,\n",
        "                 \"resnet18.onnx\",\n",
        "                 verbose=False,\n",
        "                 input_names=input_names,\n",
        "                 output_names=output_names,\n",
        "                 export_params=True,\n",
        "                 )"
      ],
      "metadata": {
        "id": "7D7W7f3Gehjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "NZVhHmdGekMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827635bf-4cbf-4cc2-c933-ad600ea98270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n",
            "Installing collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.1 protobuf-3.20.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (3.20.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.3.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"resnet18.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "torch_out = model(dummy_input) #torch.randn(1, 3, 224, 224)\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)"
      ],
      "metadata": {
        "id": "tbG9kCO8evRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX Static Graph Optimization"
      ],
      "metadata": {
        "id": "PiSheVw8qj8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxoptimizer"
      ],
      "metadata": {
        "id": "E7SP7Vcdg-xD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282143ef-ba6d-4e48-c650-9f6d62197af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxoptimizer\n",
            "  Downloading onnxoptimizer-0.3.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.8/645.8 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (from onnxoptimizer) (1.13.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxoptimizer) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxoptimizer) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxoptimizer) (4.5.0)\n",
            "Installing collected packages: onnxoptimizer\n",
            "Successfully installed onnxoptimizer-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m onnxoptimizer resnet18.onnx resnet18_opt.onnx"
      ],
      "metadata": {
        "id": "v7fbL71EhAME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "def time_ort_model_evaluation(model_path):\n",
        "    sess_options = onnxruntime.SessionOptions()\n",
        "    sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "    session = onnxruntime.InferenceSession(model_path, sess_options)\n",
        "\n",
        "    time_per_inference = []\n",
        "    for _ in range(10):\n",
        "        dummy_input = torch.randn(1, 3, 224, 224)\n",
        "        # compute ONNX Runtime output prediction\n",
        "        ort_inputs = {session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
        "        start = perf_counter()\n",
        "        session.run(None, ort_inputs)\n",
        "        time_per_inference.append((1000 * (perf_counter() - start)))\n",
        "\n",
        "    return np.mean(time_per_inference)\n",
        "\n",
        "print('Average runtime of ONNX Model in GPU: ' + str(time_ort_model_evaluation('resnet18.onnx')))\n",
        "print('Average runtime of ONNX Optimized Model in GPU: ' + str(time_ort_model_evaluation('resnet18_opt.onnx')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqOB8STgTzwQ",
        "outputId": "4e7ed9c7-6e6c-4e24-b1de-477d64f5983d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average runtime of ONNX Model in GPU: 52.80123090000188\n",
            "Average runtime of ONNX Optimized Model in GPU: 43.55868289999307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX Runtime Optimization - Quantization"
      ],
      "metadata": {
        "id": "jpR-Dw8Hqp7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "def quantize_onnx_model(onnx_model_path, quantized_model_path):\n",
        "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "    import onnx\n",
        "    onnx_opt_model = onnx.load(onnx_model_path)\n",
        "    quantize_dynamic(onnx_model_path,\n",
        "                     quantized_model_path,\n",
        "                     weight_type=QuantType.QUInt8) #QInt8\n",
        "\n",
        "    print(f\"quantized model saved to:{quantized_model_path}\")\n",
        "\n",
        "quantize_onnx_model('resnet18_opt.onnx', 'resnet18_opt_quant.onnx')\n",
        "\n",
        "print('ONNX full precision model size (MB):', os.path.getsize(\"resnet18_opt.onnx\")/(1024*1024))\n",
        "print('ONNX quantized model size (MB):', os.path.getsize(\"resnet18_opt_quant.onnx\")/(1024*1024))"
      ],
      "metadata": {
        "id": "I2orrpL-lW8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b453a5-0d32-457f-b109-cc46bbd475d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quantized model saved to:resnet18_opt_quant.onnx\n",
            "ONNX full precision model size (MB): 44.58288764953613\n",
            "ONNX quantized model size (MB): 11.200801849365234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantization on GPU**\n",
        "\n",
        "\n",
        "Hardware support is required to achieve better performance with quantization on GPUs. You need a device that supports Tensor Core int8 computation, like T4 or A100. Older hardware will not benefit from quantization."
      ],
      "metadata": {
        "id": "4Kd8ETjvo5Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Comparison of ONNX and ONNX Quantized Models"
      ],
      "metadata": {
        "id": "wmxtcRwTrqXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "def time_ort_model_evaluation(model_path):\n",
        "    sess_options = onnxruntime.SessionOptions()\n",
        "    sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "    session = onnxruntime.InferenceSession(model_path, sess_options)\n",
        "\n",
        "    time_per_inference = []\n",
        "    for _ in range(10):\n",
        "        dummy_input = torch.randn(1, 3, 224, 224)\n",
        "        # compute ONNX Runtime output prediction\n",
        "        ort_inputs = {session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
        "        start = perf_counter()\n",
        "        session.run(None, ort_inputs)\n",
        "        time_per_inference.append((1000 * (perf_counter() - start)))\n",
        "\n",
        "    return np.mean(time_per_inference)\n",
        "\n",
        "print('Average runtime of ONNX Model in TPU: ' + str(time_ort_model_evaluation('resnet18.onnx')))\n",
        "print('Average runtime of ONNX Quantized Model in TPU: ' + str(time_ort_model_evaluation('resnet18_opt_quant.onnx')))\n"
      ],
      "metadata": {
        "id": "i7Zn3fwflW_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f126dc86-e553-4110-a97e-728d2cc89226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average runtime of ONNX Model in GPU: 30.944632099988212\n",
            "Average runtime of ONNX Quantized Model in GPU: 50.33703259999811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing ONNX Models"
      ],
      "metadata": {
        "id": "3oG4hT4GrCRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netron"
      ],
      "metadata": {
        "id": "MayHUwOhoq2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21dac55-38e4-438a-8cc0-891f77b16fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting netron\n",
            "  Downloading netron-6.7.6-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: netron\n",
            "Successfully installed netron-6.7.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import netron\n",
        "netron.start('resnet18.onnx')\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_iframe(8081, height='800')"
      ],
      "metadata": {
        "id": "_ULIKLNHlXCl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "17d5e0b6-04fb-460c-f158-f10d82da6413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serving 'resnet18.onnx' at http://localhost:23825\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8081, \"/\", \"100%\", \"800\", false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import netron\n",
        "from google.colab import output\n",
        "import portpicker\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start('resnet18_opt_quant.onnx', port, browse=False)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')\n"
      ],
      "metadata": {
        "id": "wENEtVAclXFF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "f3da3610-beab-4c0e-dad1-726832322494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(21862, \"/\", \"100%\", \"800\", false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import netron\n",
        "from google.colab import output\n",
        "import portpicker\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start('resnet18.onnx', port, browse=False)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ],
      "metadata": {
        "id": "D2ERvtBuiI3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "83704374-41e1-4089-c75d-8195ee14003e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(17905, \"/\", \"100%\", \"800\", false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8Jar7MSWwDm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}